<div class="Box-sc-g0xbh4-0 QkQOb js-snippet-clipboard-copy-unpositioned" data-hpc="true"><article class="markdown-body entry-content container-lg" itemprop="text"><p align="center" dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/stanford-oval/storm/blob/main/assets/logo.svg"><img src="https://github.com/stanford-oval/storm/raw/main/assets/logo.svg" style="width: 25%; max-width: 100%;"></a>
</p>
<div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="136980129" _msthash="231">STORM：通过检索和多视角提问综合主题大纲</h1><a id="user-content-storm-synthesis-of-topic-outlines-through-retrieval-and-multi-perspective-question-asking" class="anchor" aria-label="永久链接： STORM： 通过检索和多视角提问综合主题大纲" href="#storm-synthesis-of-topic-outlines-through-retrieval-and-multi-perspective-question-asking" _mstaria-label="6271083" _msthash="232"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p align="center" dir="auto" _msttexthash="81729297" _msthash="233">|<a href="http://storm.genie.stanford.edu" rel="nofollow" _istranslated="1"><b _istranslated="1">研究预览</b></a> |<a href="https://arxiv.org/abs/2402.14207" rel="nofollow" _istranslated="1"><b _istranslated="1">风暴纸业</b></a>|<a href="https://www.arxiv.org/abs/2408.15232" rel="nofollow" _istranslated="1"><b _istranslated="1">Co-STORM 纸业</b></a> |<a href="https://storm-project.stanford.edu/" rel="nofollow" _istranslated="1"><b _istranslated="1">网站</b></a> |</p>
<p dir="auto" _msttexthash="25255347" _msthash="234"><strong _istranslated="1"></strong> 🔥 最新消息</p>
<ul dir="auto">
<li>
<p dir="auto"><font _mstmutation="1" _msttexthash="266110039" _msthash="235">[2024 年 9 月] Co-STORM 代码库现已发布，并集成到 python 包 v1.0.0 中。跑去看看。</font><code>knowledge-storm</code><code>pip install knowledge-storm --upgrade</code></p>
</li>
<li>
<p dir="auto" _msttexthash="500471803" _msthash="236">[2024/09] 我们推出了协作 STORM （Co-STORM） 来支持人类-AI 协作知识策展！<a href="https://www.arxiv.org/abs/2408.15232" rel="nofollow" _istranslated="1">Co-STORM Paper</a> 已被 EMNLP 2024 主会议接受。</p>
</li>
<li>
<p dir="auto"><font _mstmutation="1" _msttexthash="61200581" _msthash="237">[2024/07] 您现在可以使用 ！</font><code>pip install knowledge-storm</code></p>
</li>
<li>
<p dir="auto"><font _mstmutation="1" _msttexthash="533922935" _msthash="238">[2024/07] 我们增加了对用户提供的文档的支持，补充了对搜索引擎的现有支持 （， ）。（查看 <a href="https://github.com/stanford-oval/storm/pull/58" data-hovercard-type="pull_request" data-hovercard-url="/stanford-oval/storm/pull/58/hovercard" _mstmutation="1" _istranslated="1">#58</a></font><code>VectorRM</code><code>YouRM</code><code>BingSearch</code>)</p>
</li>
<li>
<p dir="auto"><font _mstmutation="1" _msttexthash="834833662" _msthash="239">[2024/07] 我们为开发者发布 demo light，这是一个使用 Python streamlit 框架构建的最小用户界面，方便本地开发和演示托管（查看 <a href="https://github.com/stanford-oval/storm/pull/54" data-hovercard-type="pull_request" data-hovercard-url="/stanford-oval/storm/pull/54/hovercard" _mstmutation="1" _istranslated="1">#54</a></font>)</p>
</li>
<li>
<p dir="auto" _msttexthash="538185271" _msthash="240">[2024/06] 我们将在 NAACL 2024 上展示 STORM！在 6 月 17 日的 Poster Session 2 上找到我们，或查看我们的<a href="/stanford-oval/storm/blob/main/assets/storm_naacl2024_slides.pdf" _istranslated="1">演示材料</a>。</p>
</li>
<li>
<p dir="auto"><font _mstmutation="1" _msttexthash="499007496" _msthash="241">[2024/05] 我们在 <a href="/stanford-oval/storm/blob/main/knowledge_storm/rm.py" _mstmutation="1" _istranslated="1">rm.py</a> 中新增 Bing Search 支持。测试 STORM - 我们现在使用 model 在演示中配置文章生成部分。</font><code>GPT-4o</code><code>GPT-4o</code></p>
</li>
<li>
<p dir="auto" _msttexthash="1789065187" _msthash="242">[2024/04] 我们发布了 STORM 代码库的重构版本！我们为 STORM <a href="/stanford-oval/storm/blob/main/knowledge_storm/interface.py" _istranslated="1">管道定义了接口</a>并重新实现 STORM-wiki（查看 <a href="/stanford-oval/storm/blob/main/knowledge_storm/storm_wiki" _istranslated="1"><code _istranslated="1">src/storm_wiki</code></a>）来演示如何实例化管道。我们提供 API 来支持不同语言模型的自定义和检索/搜索集成。</p>
</li>
</ul>
<p dir="auto"><a href="https://github.com/psf/black"><img src="https://camo.githubusercontent.com/5bf9e9fa18966df7cb5fac7715bef6b72df15e01a6efa9d616c83f9fcb527fe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667" alt="代码样式：黑色" data-canonical-src="https://img.shields.io/badge/code%20style-black-000000.svg" style="max-width: 100%;" _mstalt="274716" _msthash="243"></a></p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="47931702" _msthash="244">概述<a href="https://storm.genie.stanford.edu/" rel="nofollow" _istranslated="1">（立即试用 STORM！</a></h2><a id="user-content-overview-try-storm-now" class="anchor" aria-label="永久链接：概述（立即试用 STORM！" href="#overview-try-storm-now" _mstaria-label="855361" _msthash="245"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p align="center" dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/stanford-oval/storm/blob/main/assets/overview.svg"><img src="https://github.com/stanford-oval/storm/raw/main/assets/overview.svg" style="width: 90%; max-width: 100%;"></a>
</p><font _mstmutation="1" _msttexthash="1414227659" _msthash="246">STORM 是一个 LLM 系统，它基于 Internet 搜索从头开始编写类似 Wikipedia 的文章。Co-STORM 通过使人类协作 LLM 系统支持更一致和首选的信息搜索和知识管理，进一步增强了其功能。</font><p dir="auto" _msttexthash="643434636" _msthash="247">虽然该系统无法生成通常需要大量编辑的可发表文章，但经验丰富的维基百科编辑发现它在他们的预编写阶段很有帮助。</p>
<p dir="auto"><strong _msttexthash="895532807" _msthash="248">超过 70,000 人试用了我们的<a href="https://storm.genie.stanford.edu/" rel="nofollow" _istranslated="1">实时研究预览</a>。尝试一下，看看 STORM 如何帮助您的知识探索之旅，并提供反馈以帮助我们改进系统🙏！</strong></p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="29598491" _msthash="249">STORM &amp; Co-STORM如何运作</h2><a id="user-content-how-storm--co-storm-works" class="anchor" aria-label="永久链接：STORM &amp; Co-STORM如何运作" href="#how-storm--co-storm-works" _mstaria-label="1047878" _msthash="250"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="6294106" _msthash="251">风暴</h3><a id="user-content-storm" class="anchor" aria-label="永久链接：STORM" href="#storm" _mstaria-label="246558" _msthash="252"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="156122018" _msthash="253">STORM 将生成带有引用的长篇文章分为两个步骤：</p>
<ol dir="auto">
<li _msttexthash="253674616" _msthash="254"><strong _istranslated="1">写作前阶段</strong>：系统进行基于 Internet 的研究以收集参考文献并生成大纲。</li>
<li _msttexthash="208216736" _msthash="255"><strong _istranslated="1">写作阶段</strong>：系统使用大纲和参考文献生成带有引文的长篇文章。</li>
</ol>
<p align="center" dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/stanford-oval/storm/blob/main/assets/two_stages.jpg"><img src="https://github.com/stanford-oval/storm/raw/main/assets/two_stages.jpg" style="width: 60%; max-width: 100%;"></a>
</p>
<p dir="auto" _msttexthash="973851541" _msthash="256">STORM 将研究过程自动化的核心确定为自动提出好问题。直接提示语言模型提出问题效果不佳。为了提高问题的深度和广度，STORM 采用了两种策略：</p>
<ol dir="auto">
<li _msttexthash="710925592" _msthash="257"><strong _istranslated="1">观点引导式提问</strong>：给定输入主题，STORM 通过调查来自相似主题的现有文章来发现不同的观点，并使用它们来控制提问过程。</li>
<li _msttexthash="897629733" _msthash="258"><strong _istranslated="1">模拟对话</strong>：STORM 模拟 Wikipedia 作者与基于 Internet 资源的主题专家之间的对话，使语言模型能够更新其对主题的理解并提出后续问题。</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="13221546" _msthash="259">联合风暴</h3><a id="user-content-co-storm" class="anchor" aria-label="永久链接：CO-STORM" href="#co-storm" _mstaria-label="306761" _msthash="260"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="318154824" _msthash="261">Co-STORM 提出了<strong _istranslated="1">一种协作话语协议</strong>，该协议实施了轮流管理策略，以支持</p>
<ul dir="auto">
<li _msttexthash="493389468" _msthash="262"><strong _istranslated="1">Co-STORM LLM 专家</strong>：这种类型的代理根据外部知识来源生成答案和/或根据话语历史提出后续问题。</li>
<li _msttexthash="774015034" _msthash="263"><strong _istranslated="1">主持人</strong>：这个代理会生成发人深省的问题，其灵感来自猎犬发现的信息，但在前几轮比赛中没有直接使用。问题生成也可以接地气！</li>
<li _msttexthash="776182797" _msthash="264"><strong _istranslated="1">人类用户</strong>：人类用户将主动 （1） 观察话语以更深入地了解主题，或 （2） 通过注入话语来引导讨论焦点，从而积极参与对话。</li>
</ul>
<p align="center" dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/stanford-oval/storm/blob/main/assets/co-storm-workflow.jpg"><img src="https://github.com/stanford-oval/storm/raw/main/assets/co-storm-workflow.jpg" style="width: 60%; max-width: 100%;"></a>
</p>
<p dir="auto" _msttexthash="1764874423" _msthash="265">Co-STORM 还维护了一个动态更新的<strong _istranslated="1">思维导图</strong>，将收集到的信息组织成一个分层的概念结构，旨在<strong _istranslated="1">构建人类用户和系统之间的共享概念空间</strong>。思维导图已被证明有助于减轻长时间深入的讨论时的精神负担。</p>
<p dir="auto" _msttexthash="186530344" _msthash="266">STORM 和 Co-STORM 都是使用 <a href="https://github.com/stanfordnlp/dspy" _istranslated="1">dspy</a> 以高度模块化的方式实现的。</p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="5773755" _msthash="267">安装</h2><a id="user-content-installation" class="anchor" aria-label="永久链接：安装" href="#installation" _mstaria-label="519259" _msthash="268"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="73642751" _msthash="269">要安装 knowledge storm 库，请使用 。</font><code>pip install knowledge-storm</code></p>
<p dir="auto" _msttexthash="142673739" _msthash="270">您还可以安装源代码，以便直接修改 STORM 引擎的行为。</p>
<ol dir="auto">
<li>
<p dir="auto" _msttexthash="19883994" _msthash="271">克隆 git 存储库。</p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>git clone https://github.com/stanford-oval/storm.git
<span class="pl-c1">cd</span> storm</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="git clone https://github.com/stanford-oval/storm.git
cd storm" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
</li>
<li>
<p dir="auto" _msttexthash="33489365" _msthash="272">安装所需的软件包。</p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>conda create -n storm python=3.11
conda activate storm
pip install -r requirements.txt</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="conda create -n storm python=3.11
conda activate storm
pip install -r requirements.txt" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
</li>
</ol>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="19122688" _msthash="273">应用程序接口</h2><a id="user-content-api" class="anchor" aria-label="永久链接： API" href="#api" _mstaria-label="197821" _msthash="274"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="63786255" _msthash="275">目前，我们的软件包支持：</p>
<ul dir="auto">
<li><code>OpenAIModel</code><font _mstmutation="1" _msttexthash="41429687" _msthash="276">、、、 作为语言模型组件</font><code>AzureOpenAIModel</code><code>ClaudeModel</code><code>VLLMClient</code><code>TGIClient</code><code>TogetherClient</code><code>OllamaClient</code><code>GoogleModel</code><code>DeepSeekModel</code><code>GroqModel</code></li>
<li><code>YouRM</code><font _mstmutation="1" _msttexthash="36375170" _msthash="277">、 和 作为检索模块组件</font><code>BingSearch</code><code>VectorRM</code><code>SerperRM</code><code>BraveRM</code><code>SearXNG</code><code>DuckDuckGoSearchRM</code><code>TavilySearchRM</code><code>GoogleSearch</code><code>AzureAISearch</code></li>
</ul>
<p dir="auto" _msttexthash="457352805" _msthash="278">🌟 <strong _istranslated="1">非常感谢将更多语言模型集成到 <a href="/stanford-oval/storm/blob/main/knowledge_storm/lm.py" _istranslated="1">knowledge_storm/lm.py</a> 中以及将搜索引擎/检索器集成到 <a href="/stanford-oval/storm/blob/main/knowledge_storm/rm.py" _istranslated="1">knowledge_storm/rm.py</a> 中的 PR！</strong></p>
<p dir="auto"><font _mstmutation="1" _msttexthash="525057767" _msthash="279">STORM 和 Co-STORM 都工作在信息管理层，你需要设置信息检索模块和语言模型模块来分别创建它们的类。</font><code>Runner</code></p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="6294106" _msthash="280">风暴</h3><a id="user-content-storm-1" class="anchor" aria-label="永久链接：STORM" href="#storm-1" _mstaria-label="246558" _msthash="281"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="351523458" _msthash="282">STORM 知识管理引擎定义为一个简单的 Python 类。以下是使用 You.com 搜索引擎和 OpenAI 模型的示例。</font><code>STORMWikiRunner</code></p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-k">import</span> <span class="pl-s1">os</span>
<span class="pl-k">from</span> <span class="pl-s1">knowledge_storm</span> <span class="pl-k">import</span> <span class="pl-v">STORMWikiRunnerArguments</span>, <span class="pl-v">STORMWikiRunner</span>, <span class="pl-v">STORMWikiLMConfigs</span>
<span class="pl-k">from</span> <span class="pl-s1">knowledge_storm</span>.<span class="pl-s1">lm</span> <span class="pl-k">import</span> <span class="pl-v">OpenAIModel</span>
<span class="pl-k">from</span> <span class="pl-s1">knowledge_storm</span>.<span class="pl-s1">rm</span> <span class="pl-k">import</span> <span class="pl-v">YouRM</span>

<span class="pl-s1">lm_configs</span> <span class="pl-c1">=</span> <span class="pl-v">STORMWikiLMConfigs</span>()
<span class="pl-s1">openai_kwargs</span> <span class="pl-c1">=</span> {
    <span class="pl-s">'api_key'</span>: <span class="pl-s1">os</span>.<span class="pl-en">getenv</span>(<span class="pl-s">"OPENAI_API_KEY"</span>),
    <span class="pl-s">'temperature'</span>: <span class="pl-c1">1.0</span>,
    <span class="pl-s">'top_p'</span>: <span class="pl-c1">0.9</span>,
}
<span class="pl-c"># STORM is a LM system so different components can be powered by different models to reach a good balance between cost and quality.</span>
<span class="pl-c"># For a good practice, choose a cheaper/faster model for `conv_simulator_lm` which is used to split queries, synthesize answers in the conversation.</span>
<span class="pl-c"># Choose a more powerful model for `article_gen_lm` to generate verifiable text with citations.</span>
<span class="pl-s1">gpt_35</span> <span class="pl-c1">=</span> <span class="pl-v">OpenAIModel</span>(<span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s">'gpt-3.5-turbo'</span>, <span class="pl-s1">max_tokens</span><span class="pl-c1">=</span><span class="pl-c1">500</span>, <span class="pl-c1">**</span><span class="pl-s1">openai_kwargs</span>)
<span class="pl-s1">gpt_4</span> <span class="pl-c1">=</span> <span class="pl-v">OpenAIModel</span>(<span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s">'gpt-4o'</span>, <span class="pl-s1">max_tokens</span><span class="pl-c1">=</span><span class="pl-c1">3000</span>, <span class="pl-c1">**</span><span class="pl-s1">openai_kwargs</span>)
<span class="pl-s1">lm_configs</span>.<span class="pl-en">set_conv_simulator_lm</span>(<span class="pl-s1">gpt_35</span>)
<span class="pl-s1">lm_configs</span>.<span class="pl-en">set_question_asker_lm</span>(<span class="pl-s1">gpt_35</span>)
<span class="pl-s1">lm_configs</span>.<span class="pl-en">set_outline_gen_lm</span>(<span class="pl-s1">gpt_4</span>)
<span class="pl-s1">lm_configs</span>.<span class="pl-en">set_article_gen_lm</span>(<span class="pl-s1">gpt_4</span>)
<span class="pl-s1">lm_configs</span>.<span class="pl-en">set_article_polish_lm</span>(<span class="pl-s1">gpt_4</span>)
<span class="pl-c"># Check out the STORMWikiRunnerArguments class for more configurations.</span>
<span class="pl-s1">engine_args</span> <span class="pl-c1">=</span> <span class="pl-v">STORMWikiRunnerArguments</span>(...)
<span class="pl-s1">rm</span> <span class="pl-c1">=</span> <span class="pl-v">YouRM</span>(<span class="pl-s1">ydc_api_key</span><span class="pl-c1">=</span><span class="pl-s1">os</span>.<span class="pl-en">getenv</span>(<span class="pl-s">'YDC_API_KEY'</span>), <span class="pl-s1">k</span><span class="pl-c1">=</span><span class="pl-s1">engine_args</span>.<span class="pl-s1">search_top_k</span>)
<span class="pl-s1">runner</span> <span class="pl-c1">=</span> <span class="pl-v">STORMWikiRunner</span>(<span class="pl-s1">engine_args</span>, <span class="pl-s1">lm_configs</span>, <span class="pl-s1">rm</span>)</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="import os
from knowledge_storm import STORMWikiRunnerArguments, STORMWikiRunner, STORMWikiLMConfigs
from knowledge_storm.lm import OpenAIModel
from knowledge_storm.rm import YouRM

lm_configs = STORMWikiLMConfigs()
openai_kwargs = {
    'api_key': os.getenv(&quot;OPENAI_API_KEY&quot;),
    'temperature': 1.0,
    'top_p': 0.9,
}
# STORM is a LM system so different components can be powered by different models to reach a good balance between cost and quality.
# For a good practice, choose a cheaper/faster model for `conv_simulator_lm` which is used to split queries, synthesize answers in the conversation.
# Choose a more powerful model for `article_gen_lm` to generate verifiable text with citations.
gpt_35 = OpenAIModel(model='gpt-3.5-turbo', max_tokens=500, **openai_kwargs)
gpt_4 = OpenAIModel(model='gpt-4o', max_tokens=3000, **openai_kwargs)
lm_configs.set_conv_simulator_lm(gpt_35)
lm_configs.set_question_asker_lm(gpt_35)
lm_configs.set_outline_gen_lm(gpt_4)
lm_configs.set_article_gen_lm(gpt_4)
lm_configs.set_article_polish_lm(gpt_4)
# Check out the STORMWikiRunnerArguments class for more configurations.
engine_args = STORMWikiRunnerArguments(...)
rm = YouRM(ydc_api_key=os.getenv('YDC_API_KEY'), k=engine_args.search_top_k)
runner = STORMWikiRunner(engine_args, lm_configs, rm)" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="86363628" _msthash="283">该实例可以通过简单的方法触发：</font><code>STORMWikiRunner</code><code>run</code></p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-s1">topic</span> <span class="pl-c1">=</span> <span class="pl-en">input</span>(<span class="pl-s">'Topic: '</span>)
<span class="pl-s1">runner</span>.<span class="pl-en">run</span>(
    <span class="pl-s1">topic</span><span class="pl-c1">=</span><span class="pl-s1">topic</span>,
    <span class="pl-s1">do_research</span><span class="pl-c1">=</span><span class="pl-c1">True</span>,
    <span class="pl-s1">do_generate_outline</span><span class="pl-c1">=</span><span class="pl-c1">True</span>,
    <span class="pl-s1">do_generate_article</span><span class="pl-c1">=</span><span class="pl-c1">True</span>,
    <span class="pl-s1">do_polish_article</span><span class="pl-c1">=</span><span class="pl-c1">True</span>,
)
<span class="pl-s1">runner</span>.<span class="pl-en">post_run</span>()
<span class="pl-s1">runner</span>.<span class="pl-en">summary</span>()</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="topic = input('Topic: ')
runner.run(
    topic=topic,
    do_research=True,
    do_generate_outline=True,
    do_generate_article=True,
    do_polish_article=True,
)
runner.post_run()
runner.summary()" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<ul dir="auto">
<li><code>do_research</code><font _mstmutation="1" _msttexthash="381668183" _msthash="284">：如果为 True，则模拟具有不同视角的对话以收集有关该主题的信息;否则，加载结果。</font></li>
<li><code>do_generate_outline</code><font _mstmutation="1" _msttexthash="167891412" _msthash="285">：如果为 True，则为主题生成大纲;否则，加载结果。</font></li>
<li><code>do_generate_article</code><font _mstmutation="1" _msttexthash="348057060" _msthash="286">：如果为 True，则根据大纲和收集的信息为该主题生成一篇文章;否则，加载结果。</font></li>
<li><code>do_polish_article</code><font _mstmutation="1" _msttexthash="450122530" _msthash="287">：如果为 True，则通过添加摘要部分和（可选）删除重复内容来润色文章;否则，加载结果。</font></li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="13221546" _msthash="288">联合风暴</h3><a id="user-content-co-storm-1" class="anchor" aria-label="永久链接：Co-STORM" href="#co-storm-1" _mstaria-label="314249" _msthash="289"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="371930273" _msthash="290">Co-STORM 知识管理引擎定义为一个简单的 Python 类。以下是使用 Bing 搜索引擎和 OpenAI 模型的示例。</font><code>CoStormRunner</code></p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-k">from</span> <span class="pl-s1">knowledge_storm</span>.<span class="pl-s1">collaborative_storm</span>.<span class="pl-s1">engine</span> <span class="pl-k">import</span> <span class="pl-v">CollaborativeStormLMConfigs</span>, <span class="pl-v">RunnerArgument</span>, <span class="pl-v">CoStormRunner</span>
<span class="pl-k">from</span> <span class="pl-s1">knowledge_storm</span>.<span class="pl-s1">lm</span> <span class="pl-k">import</span> <span class="pl-v">OpenAIModel</span>
<span class="pl-k">from</span> <span class="pl-s1">knowledge_storm</span>.<span class="pl-s1">logging_wrapper</span> <span class="pl-k">import</span> <span class="pl-v">LoggingWrapper</span>
<span class="pl-k">from</span> <span class="pl-s1">knowledge_storm</span>.<span class="pl-s1">rm</span> <span class="pl-k">import</span> <span class="pl-v">BingSearch</span>

<span class="pl-c"># Co-STORM adopts the same multi LM system paradigm as STORM </span>
<span class="pl-s1">lm_config</span>: <span class="pl-v">CollaborativeStormLMConfigs</span> <span class="pl-c1">=</span> <span class="pl-v">CollaborativeStormLMConfigs</span>()
<span class="pl-s1">openai_kwargs</span> <span class="pl-c1">=</span> {
    <span class="pl-s">"api_key"</span>: <span class="pl-s1">os</span>.<span class="pl-en">getenv</span>(<span class="pl-s">"OPENAI_API_KEY"</span>),
    <span class="pl-s">"api_provider"</span>: <span class="pl-s">"openai"</span>,
    <span class="pl-s">"temperature"</span>: <span class="pl-c1">1.0</span>,
    <span class="pl-s">"top_p"</span>: <span class="pl-c1">0.9</span>,
    <span class="pl-s">"api_base"</span>: <span class="pl-c1">None</span>,
} 
<span class="pl-s1">question_answering_lm</span> <span class="pl-c1">=</span> <span class="pl-v">OpenAIModel</span>(<span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s1">gpt_4o_model_name</span>, <span class="pl-s1">max_tokens</span><span class="pl-c1">=</span><span class="pl-c1">1000</span>, <span class="pl-c1">**</span><span class="pl-s1">openai_kwargs</span>)
<span class="pl-s1">discourse_manage_lm</span> <span class="pl-c1">=</span> <span class="pl-v">OpenAIModel</span>(<span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s1">gpt_4o_model_name</span>, <span class="pl-s1">max_tokens</span><span class="pl-c1">=</span><span class="pl-c1">500</span>, <span class="pl-c1">**</span><span class="pl-s1">openai_kwargs</span>)
<span class="pl-s1">utterance_polishing_lm</span> <span class="pl-c1">=</span> <span class="pl-v">OpenAIModel</span>(<span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s1">gpt_4o_model_name</span>, <span class="pl-s1">max_tokens</span><span class="pl-c1">=</span><span class="pl-c1">2000</span>, <span class="pl-c1">**</span><span class="pl-s1">openai_kwargs</span>)
<span class="pl-s1">warmstart_outline_gen_lm</span> <span class="pl-c1">=</span> <span class="pl-v">OpenAIModel</span>(<span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s1">gpt_4o_model_name</span>, <span class="pl-s1">max_tokens</span><span class="pl-c1">=</span><span class="pl-c1">500</span>, <span class="pl-c1">**</span><span class="pl-s1">openai_kwargs</span>)
<span class="pl-s1">question_asking_lm</span> <span class="pl-c1">=</span> <span class="pl-v">OpenAIModel</span>(<span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s1">gpt_4o_model_name</span>, <span class="pl-s1">max_tokens</span><span class="pl-c1">=</span><span class="pl-c1">300</span>, <span class="pl-c1">**</span><span class="pl-s1">openai_kwargs</span>)
<span class="pl-s1">knowledge_base_lm</span> <span class="pl-c1">=</span> <span class="pl-v">OpenAIModel</span>(<span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s1">gpt_4o_model_name</span>, <span class="pl-s1">max_tokens</span><span class="pl-c1">=</span><span class="pl-c1">1000</span>, <span class="pl-c1">**</span><span class="pl-s1">openai_kwargs</span>)

<span class="pl-s1">lm_config</span>.<span class="pl-en">set_question_answering_lm</span>(<span class="pl-s1">question_answering_lm</span>)
<span class="pl-s1">lm_config</span>.<span class="pl-en">set_discourse_manage_lm</span>(<span class="pl-s1">discourse_manage_lm</span>)
<span class="pl-s1">lm_config</span>.<span class="pl-en">set_utterance_polishing_lm</span>(<span class="pl-s1">utterance_polishing_lm</span>)
<span class="pl-s1">lm_config</span>.<span class="pl-en">set_warmstart_outline_gen_lm</span>(<span class="pl-s1">warmstart_outline_gen_lm</span>)
<span class="pl-s1">lm_config</span>.<span class="pl-en">set_question_asking_lm</span>(<span class="pl-s1">question_asking_lm</span>)
<span class="pl-s1">lm_config</span>.<span class="pl-en">set_knowledge_base_lm</span>(<span class="pl-s1">knowledge_base_lm</span>)

<span class="pl-c"># Check out the Co-STORM's RunnerArguments class for more configurations.</span>
<span class="pl-s1">topic</span> <span class="pl-c1">=</span> <span class="pl-en">input</span>(<span class="pl-s">'Topic: '</span>)
<span class="pl-s1">runner_argument</span> <span class="pl-c1">=</span> <span class="pl-v">RunnerArgument</span>(<span class="pl-s1">topic</span><span class="pl-c1">=</span><span class="pl-s1">topic</span>, ...)
<span class="pl-s1">logging_wrapper</span> <span class="pl-c1">=</span> <span class="pl-v">LoggingWrapper</span>(<span class="pl-s1">lm_config</span>)
<span class="pl-s1">bing_rm</span> <span class="pl-c1">=</span> <span class="pl-v">BingSearch</span>(<span class="pl-s1">bing_search_api_key</span><span class="pl-c1">=</span><span class="pl-s1">os</span>.<span class="pl-s1">environ</span>.<span class="pl-en">get</span>(<span class="pl-s">"BING_SEARCH_API_KEY"</span>),
                     <span class="pl-s1">k</span><span class="pl-c1">=</span><span class="pl-s1">runner_argument</span>.<span class="pl-s1">retrieve_top_k</span>)
<span class="pl-s1">costorm_runner</span> <span class="pl-c1">=</span> <span class="pl-v">CoStormRunner</span>(<span class="pl-s1">lm_config</span><span class="pl-c1">=</span><span class="pl-s1">lm_config</span>,
                               <span class="pl-s1">runner_argument</span><span class="pl-c1">=</span><span class="pl-s1">runner_argument</span>,
                               <span class="pl-s1">logging_wrapper</span><span class="pl-c1">=</span><span class="pl-s1">logging_wrapper</span>,
                               <span class="pl-s1">rm</span><span class="pl-c1">=</span><span class="pl-s1">bing_rm</span>)</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="from knowledge_storm.collaborative_storm.engine import CollaborativeStormLMConfigs, RunnerArgument, CoStormRunner
from knowledge_storm.lm import OpenAIModel
from knowledge_storm.logging_wrapper import LoggingWrapper
from knowledge_storm.rm import BingSearch

# Co-STORM adopts the same multi LM system paradigm as STORM 
lm_config: CollaborativeStormLMConfigs = CollaborativeStormLMConfigs()
openai_kwargs = {
    &quot;api_key&quot;: os.getenv(&quot;OPENAI_API_KEY&quot;),
    &quot;api_provider&quot;: &quot;openai&quot;,
    &quot;temperature&quot;: 1.0,
    &quot;top_p&quot;: 0.9,
    &quot;api_base&quot;: None,
} 
question_answering_lm = OpenAIModel(model=gpt_4o_model_name, max_tokens=1000, **openai_kwargs)
discourse_manage_lm = OpenAIModel(model=gpt_4o_model_name, max_tokens=500, **openai_kwargs)
utterance_polishing_lm = OpenAIModel(model=gpt_4o_model_name, max_tokens=2000, **openai_kwargs)
warmstart_outline_gen_lm = OpenAIModel(model=gpt_4o_model_name, max_tokens=500, **openai_kwargs)
question_asking_lm = OpenAIModel(model=gpt_4o_model_name, max_tokens=300, **openai_kwargs)
knowledge_base_lm = OpenAIModel(model=gpt_4o_model_name, max_tokens=1000, **openai_kwargs)

lm_config.set_question_answering_lm(question_answering_lm)
lm_config.set_discourse_manage_lm(discourse_manage_lm)
lm_config.set_utterance_polishing_lm(utterance_polishing_lm)
lm_config.set_warmstart_outline_gen_lm(warmstart_outline_gen_lm)
lm_config.set_question_asking_lm(question_asking_lm)
lm_config.set_knowledge_base_lm(knowledge_base_lm)

# Check out the Co-STORM's RunnerArguments class for more configurations.
topic = input('Topic: ')
runner_argument = RunnerArgument(topic=topic, ...)
logging_wrapper = LoggingWrapper(lm_config)
bing_rm = BingSearch(bing_search_api_key=os.environ.get(&quot;BING_SEARCH_API_KEY&quot;),
                     k=runner_argument.retrieve_top_k)
costorm_runner = CoStormRunner(lm_config=lm_config,
                               runner_argument=runner_argument,
                               logging_wrapper=logging_wrapper,
                               rm=bing_rm)" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="46828210" _msthash="291">可以使用 和 方法调用实例。</font><code>CoStormRunner</code><code>warmstart()</code><code>step(...)</code></p>
<div class="highlight highlight-source-python notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"># Warm start the system to build shared conceptual space between Co-STORM and users</span>
<span class="pl-s1">costorm_runner</span>.<span class="pl-en">warm_start</span>()

<span class="pl-c"># Step through the collaborative discourse </span>
<span class="pl-c"># Run either of the code snippets below in any order, as many times as you'd like</span>
<span class="pl-c"># To observe the conversation:</span>
<span class="pl-s1">conv_turn</span> <span class="pl-c1">=</span> <span class="pl-s1">costorm_runner</span>.<span class="pl-en">step</span>()
<span class="pl-c"># To inject your utterance to actively steer the conversation:</span>
<span class="pl-s1">costorm_runner</span>.<span class="pl-en">step</span>(<span class="pl-s1">user_utterance</span><span class="pl-c1">=</span><span class="pl-s">"YOUR UTTERANCE HERE"</span>)

<span class="pl-c"># Generate report based on the collaborative discourse</span>
<span class="pl-s1">costorm_runner</span>.<span class="pl-s1">knowledge_base</span>.<span class="pl-en">reorganize</span>()
<span class="pl-s1">article</span> <span class="pl-c1">=</span> <span class="pl-s1">costorm_runner</span>.<span class="pl-en">generate_report</span>()
<span class="pl-en">print</span>(<span class="pl-s1">article</span>)</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# Warm start the system to build shared conceptual space between Co-STORM and users
costorm_runner.warm_start()

# Step through the collaborative discourse 
# Run either of the code snippets below in any order, as many times as you'd like
# To observe the conversation:
conv_turn = costorm_runner.step()
# To inject your utterance to actively steer the conversation:
costorm_runner.step(user_utterance=&quot;YOUR UTTERANCE HERE&quot;)

# Generate report based on the collaborative discourse
costorm_runner.knowledge_base.reorganize()
article = costorm_runner.generate_report()
print(article)" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="32015126" _msthash="292">示例脚本快速入门</h2><a id="user-content-quick-start-with-example-scripts" class="anchor" aria-label="永久链接：示例脚本快速入门" href="#quick-start-with-example-scripts" _mstaria-label="1317914" _msthash="293"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="352335230" _msthash="294">我们在 <a href="/stanford-oval/storm/blob/main/examples" _istranslated="1">examples 文件夹中</a>提供了脚本，作为运行具有不同配置的 STORM 和 Co-STORM 的快速入门。</p>
<p dir="auto"><font _mstmutation="1" _msttexthash="259453844" _msthash="295">我们建议使用 来设置 API 密钥。在根目录下创建文件，并添加以下内容：</font><code>secrets.toml</code><code>secrets.toml</code></p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-c"><span class="pl-c">#</span> Set up OpenAI API key.</span>
OPENAI_API_KEY=<span class="pl-s"><span class="pl-pds">"</span>your_openai_api_key<span class="pl-pds">"</span></span>
<span class="pl-c"><span class="pl-c">#</span> If you are using the API service provided by OpenAI, include the following line:</span>
OPENAI_API_TYPE=<span class="pl-s"><span class="pl-pds">"</span>openai<span class="pl-pds">"</span></span>
<span class="pl-c"><span class="pl-c">#</span> If you are using the API service provided by Microsoft Azure, include the following lines:</span>
OPENAI_API_TYPE=<span class="pl-s"><span class="pl-pds">"</span>azure<span class="pl-pds">"</span></span>
AZURE_API_BASE=<span class="pl-s"><span class="pl-pds">"</span>your_azure_api_base_url<span class="pl-pds">"</span></span>
AZURE_API_VERSION=<span class="pl-s"><span class="pl-pds">"</span>your_azure_api_version<span class="pl-pds">"</span></span>
<span class="pl-c"><span class="pl-c">#</span> Set up You.com search API key.</span>
YDC_API_KEY=<span class="pl-s"><span class="pl-pds">"</span>your_youcom_api_key<span class="pl-pds">"</span></span></pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# Set up OpenAI API key.
OPENAI_API_KEY=&quot;your_openai_api_key&quot;
# If you are using the API service provided by OpenAI, include the following line:
OPENAI_API_TYPE=&quot;openai&quot;
# If you are using the API service provided by Microsoft Azure, include the following lines:
OPENAI_API_TYPE=&quot;azure&quot;
AZURE_API_BASE=&quot;your_azure_api_base_url&quot;
AZURE_API_VERSION=&quot;your_azure_api_version&quot;
# Set up You.com search API key.
YDC_API_KEY=&quot;your_youcom_api_key&quot;" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="8329854" _msthash="296">STORM 示例</h3><a id="user-content-storm-examples" class="anchor" aria-label="永久链接：STORM 示例" href="#storm-examples" _mstaria-label="532896" _msthash="297"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong _msttexthash="107712722" _msthash="298">要使用默认配置的 <code _istranslated="1">gpt</code> 系列模型运行 STORM：</strong></p>
<p dir="auto" _msttexthash="20259876" _msthash="299">运行以下命令。</p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>python examples/storm_examples/run_storm_wiki_gpt.py \
    --output-dir <span class="pl-smi">$OUTPUT_DIR</span> \
    --retriever you \
    --do-research \
    --do-generate-outline \
    --do-generate-article \
    --do-polish-article</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="python examples/storm_examples/run_storm_wiki_gpt.py \
    --output-dir $OUTPUT_DIR \
    --retriever you \
    --do-research \
    --do-generate-outline \
    --do-generate-article \
    --do-polish-article" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto" _msttexthash="236751619" _msthash="300"><strong _istranslated="1">要使用您最喜欢的语言模型或基于您自己的语料库运行 STORM：</strong>查看 <a href="/stanford-oval/storm/blob/main/examples/storm_examples/README.md" _istranslated="1">examples/storm_examples/README.md</a>。</p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="10373038" _msthash="301">Co-STORM 示例</h3><a id="user-content-co-storm-examples" class="anchor" aria-label="永久链接：Co-STORM 示例" href="#co-storm-examples" _mstaria-label="634244" _msthash="302"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="109561686" _msthash="303">要使用具有默认配置的族模型运行 Co-STORM，</font><code>gpt</code></p>
<ol dir="auto">
<li><font _mstmutation="1" _msttexthash="2875639" _msthash="304">Add 和 to</font><code>BING_SEARCH_API_KEY="xxx"</code><code>ENCODER_API_TYPE="xxx"</code><code>secrets.toml</code></li>
<li _msttexthash="18182866" _msthash="305">运行以下命令</li>
</ol>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>python examples/costorm_examples/run_costorm_gpt.py \
    --output-dir <span class="pl-smi">$OUTPUT_DIR</span> \
    --retriever bing</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="python examples/costorm_examples/run_costorm_gpt.py \
    --output-dir $OUTPUT_DIR \
    --retriever bing" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="21075613" _msthash="306">管道的自定义</h2><a id="user-content-customization-of-the-pipeline" class="anchor" aria-label="永久链接：管道的自定义" href="#customization-of-the-pipeline" _mstaria-label="1202201" _msthash="307"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="6294106" _msthash="308">风暴</h3><a id="user-content-storm-2" class="anchor" aria-label="永久链接：STORM" href="#storm-2" _mstaria-label="246558" _msthash="309"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="373313837" _msthash="310">如果您已经安装了源代码，则可以根据自己的使用案例自定义 STORM。STORM 引擎由 4 个模块组成：</p>
<ol dir="auto">
<li _msttexthash="127996284" _msthash="311">知识管理模块：收集有关给定主题的广泛信息。</li>
<li _msttexthash="225547114" _msthash="312">大纲生成模块：通过为精选知识生成分层大纲来组织收集的信息。</li>
<li _msttexthash="135218382" _msthash="313">文章生成模块：使用收集的信息填充生成的大纲。</li>
<li _msttexthash="140533653" _msthash="314">文章润色模块：提炼和增强书面文章以更好地呈现。</li>
</ol>
<p dir="auto"><font _mstmutation="1" _msttexthash="1006798611" _msthash="315">每个模块的接口在 中定义，而它们的实现在 中实例化。这些模块可以根据您的特定要求进行自定义（例如，以项目符号格式而不是完整段落生成部分）。</font><code>knowledge_storm/interface.py</code><code>knowledge_storm/storm_wiki/modules/*</code></p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="13221546" _msthash="316">联合风暴</h3><a id="user-content-co-storm-2" class="anchor" aria-label="永久链接：Co-STORM" href="#co-storm-2" _mstaria-label="314249" _msthash="317"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="178281909" _msthash="318">如果您已经安装了源码，则可以根据自己的使用案例自定义 Co-STORM</p>
<ol dir="auto">
<li><font _mstmutation="1" _msttexthash="854152871" _msthash="319">Co-STORM 引入了多种 LLM 代理类型（即 Co-STORM 专家和主持人）。LLM 代理接口在 中定义，而其实现在 中实例化。可以自定义不同的 LLM 代理策略。</font><code>knowledge_storm/interface.py</code><code>knowledge_storm/collaborative_storm/modules/co_storm_agents.py</code></li>
<li><font _mstmutation="1" _msttexthash="774269197" _msthash="320">Co-STORM 引入了协作话语协议，其核心功能以轮次策略管理为中心。我们提供了一个 turn policy management 的实施示例。它可以定制并进一步改进。</font><code>DiscourseManager</code><code>knowledge_storm/collaborative_storm/engine.py</code></li>
</ol>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="5010304" _msthash="321">数据</h2><a id="user-content-datasets" class="anchor" aria-label="永久链接：数据集" href="#datasets" _mstaria-label="369148" _msthash="322"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="327423993" _msthash="323">为了促进自动知识管理和复杂信息搜索的研究，我们的项目发布了以下数据集：</p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="13268840" _msthash="324">新鲜维基</h3><a id="user-content-freshwiki" class="anchor" aria-label="永久链接：FreshWiki" href="#freshwiki" _mstaria-label="395876" _msthash="325"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="1119939743" _msthash="326">FreshWiki 数据集是 100 篇高质量维基百科文章的集合，专注于 2022 年 2 月至 2023 年 9 月期间编辑次数最多的页面。有关详细信息，请参阅 <a href="https://arxiv.org/abs/2402.14207" rel="nofollow" _istranslated="1">STORM 论文</a>中的第 2.1 节。</p>
<p dir="auto" _msttexthash="663354744" _msthash="327">您可以直接从 <a href="https://huggingface.co/datasets/EchoShao8899/FreshWiki" rel="nofollow" _istranslated="1">huggingface</a> 下载数据集。为了缓解数据污染问题，我们将数据构建管道的<a href="https://github.com/stanford-oval/storm/tree/NAACL-2024-code-backup/FreshWiki" _istranslated="1">源代码</a>存档，以便将来重复。</p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="13854867" _msthash="328">野生寻觅</h3><a id="user-content-wildseek" class="anchor" aria-label="永久链接：WildSeek" href="#wildseek" _mstaria-label="358306" _msthash="329"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="3870051510" _msthash="330">为了研究用户对在野外进行复杂信息搜索任务的兴趣，我们利用从 Web 研究预览中收集的数据来创建 WildSeek 数据集。我们对数据进行了缩减采样，以确保主题的多样性和数据的质量。每个数据点都是一对，其中包含一个主题和用户对该主题进行深入搜索的目标。有关更多详细信息，请参阅 <a href="https://www.arxiv.org/abs/2408.15232" rel="nofollow" _istranslated="1">Co-STORM 论文</a>的第 2.2 节和附录 A。</p>
<p dir="auto" _msttexthash="63700000" _msthash="331">WildSeek 数据集可<a href="https://huggingface.co/datasets/YuchengJiang/WildSeek" rel="nofollow" _istranslated="1">在此处</a>获得。</p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="42800485" _msthash="332">复制 STORM &amp; Co-STORM 论文结果</h2><a id="user-content-replicate-storm--co-storm-paper-result" class="anchor" aria-label="永久链接：复制 STORM &amp; Co-STORM 论文结果" href="#replicate-storm--co-storm-paper-result" _mstaria-label="1817959" _msthash="333"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="117896961" _msthash="334">对于 STORM 论文实验，请切换到<a href="https://github.com/stanford-oval/storm/tree/NAACL-2024-code-backup" _mstmutation="1" _istranslated="1">此处</a>的分支。</font><code>NAACL-2024-code-backup</code></p>
<p dir="auto"><font _mstmutation="1" _msttexthash="300528540" _msthash="335">对于 Co-STORM 论文实验，请切换到分支（目前为占位符，即将更新）。</font><code>EMNLP-2024-code-backup</code></p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="21866546" _msthash="336">路线图和贡献</h2><a id="user-content-roadmap--contributions" class="anchor" aria-label="永久链接：路线图和贡献" href="#roadmap--contributions" _mstaria-label="1110993" _msthash="337"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="67659566" _msthash="338">我们的团队正在积极致力于：</p>
<ol dir="auto">
<li _msttexthash="121964739" _msthash="339">人机协同功能：支持用户参与知识管理过程。</li>
<li _msttexthash="265218863" _msthash="340">信息抽象：为精选信息开发抽象，以支持 Wikipedia 样式报告之外的表示格式。</li>
</ol>
<p dir="auto" _msttexthash="470916355" _msthash="341">如果您有任何问题或建议，请随时打开 issue 或 pull request。我们欢迎为改进系统和代码库做出贡献！</p>
<p dir="auto" _msttexthash="49549903" _msthash="342">联系人：<a href="mailto:shaoyj@stanford.edu" _istranslated="1">邵毅佳</a>、<a href="mailto:yuchengj@stanford.edu" _istranslated="1">江玉成</a></p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="6523322" _msthash="343">确认</h2><a id="user-content-acknowledgement" class="anchor" aria-label="永久链接：致谢" href="#acknowledgement" _mstaria-label="637572" _msthash="344"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="830383710" _msthash="345">我们要感谢 Wikipedia 出色的开源内容。FreshWiki 数据集来源于维基百科，根据知识共享署名-相同方式共享 （CC BY-SA） 许可获得许可。</p>
<p dir="auto" _msttexthash="264668599" _msthash="346">我们非常感谢 <a href="https://michelle123lam.github.io/" rel="nofollow" _istranslated="1">Michelle Lam</a> 为这个项目设计了 logo，感谢 <a href="https://dekun.me" rel="nofollow" _istranslated="1">Dekun 马</a> 领导 UI 开发。</p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="4918095" _msthash="347">引文</h2><a id="user-content-citation" class="anchor" aria-label="永久链接： 引文" href="#citation" _mstaria-label="369161" _msthash="348"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="239598931" _msthash="349">如果您在工作中使用此代码或其中的一部分，请引用我们的论文：</p>
<div class="highlight highlight-text-bibtex notranslate position-relative overflow-auto" dir="auto"><pre><span class="pl-k">@misc</span>{<span class="pl-en">jiang2024unknownunknowns</span>,
      <span class="pl-s">title</span>=<span class="pl-s"><span class="pl-pds">{</span>Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations<span class="pl-pds">}</span></span>, 
      <span class="pl-s">author</span>=<span class="pl-s"><span class="pl-pds">{</span>Yucheng Jiang and Yijia Shao and Dekun Ma and Sina J. Semnani and Monica S. Lam<span class="pl-pds">}</span></span>,
      <span class="pl-s">year</span>=<span class="pl-s"><span class="pl-pds">{</span>2024<span class="pl-pds">}</span></span>,
      <span class="pl-s">eprint</span>=<span class="pl-s"><span class="pl-pds">{</span>2408.15232<span class="pl-pds">}</span></span>,
      <span class="pl-s">archivePrefix</span>=<span class="pl-s"><span class="pl-pds">{</span>arXiv<span class="pl-pds">}</span></span>,
      <span class="pl-s">primaryClass</span>=<span class="pl-s"><span class="pl-pds">{</span>cs.CL<span class="pl-pds">}</span></span>,
      <span class="pl-s">url</span>=<span class="pl-s"><span class="pl-pds">{</span>https://arxiv.org/abs/2408.15232<span class="pl-pds">}</span></span>, 
}

<span class="pl-k">@inproceedings</span>{<span class="pl-en">shao2024assisting</span>,
      <span class="pl-s">title</span>=<span class="pl-s"><span class="pl-pds">{</span>{Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models}<span class="pl-pds">}</span></span>, 
      <span class="pl-s">author</span>=<span class="pl-s"><span class="pl-pds">{</span>Yijia Shao and Yucheng Jiang and Theodore A. Kanell and Peter Xu and Omar Khattab and Monica S. Lam<span class="pl-pds">}</span></span>,
      <span class="pl-s">year</span>=<span class="pl-s"><span class="pl-pds">{</span>2024<span class="pl-pds">}</span></span>,
      <span class="pl-s">booktitle</span>=<span class="pl-s"><span class="pl-pds">{</span>Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)<span class="pl-pds">}</span></span>
}</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="@misc{jiang2024unknownunknowns,
      title={Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations}, 
      author={Yucheng Jiang and Yijia Shao and Dekun Ma and Sina J. Semnani and Monica S. Lam},
      year={2024},
      eprint={2408.15232},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.15232}, 
}

@inproceedings{shao2024assisting,
      title={{Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models}}, 
      author={Yijia Shao and Yucheng Jiang and Theodore A. Kanell and Peter Xu and Omar Khattab and Monica S. Lam},
      year={2024},
      booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)}
}" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
</article></div>
